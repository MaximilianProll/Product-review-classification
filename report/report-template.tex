\documentclass[a4paper,11pt]{article}

\usepackage[english]{babel} 			%% englische Sprache

\usepackage[latin1,applemac]{inputenc}	%% deutsche Umlaute wie normale
 								%% Buchstaben verwenden 
 								%% (ansonsten muesste ‰ durch a getippt werden)
\usepackage{a4wide} 				%% kleinere Seitenränder

\usepackage{amssymb,amsthm,amsfonts, amsmath}
								%% diverse Matheerweiterungen, z.B. \implies
 								%% diverse Matheerweiterungen, z.B. \mathbb{R}
%\usepackage{stmaryrd} 				%% weitere Symbole
\usepackage{epsfig} 					%% um eps-Dateien einzubinden (\epsfig{file=...})
\usepackage{longtable} 				%% fuer Tabellen ueber mehrere Seiten
\usepackage{color}
\usepackage{hyperref}
\usepackage{dsfont}
\usepackage{caption}
\usepackage{multirow}
\usepackage{float}

\hypersetup{						%get rid of red box around hyperlink
pdfborder = {0 0 0}
}

\usepackage{listings} 				% noice code inclusion
\usepackage{color}

\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\lstset{
	frame=single,
	language=Python,
	belowcaptionskip=1\baselineskip,
	breaklines=true,
	frame=tb,
	showstringspaces=false,
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\color{deepblue},
	emphstyle=\color{deepred},    		% Custom highlighting style
	stringstyle=\color{deepgreen},
	commentstyle=\itshape\color{deepgreen}
}
\usepackage{enumerate}

\begin{document}

\title{Title of the Mini Project\\
\normalsize (MP 004 Firing Neurons)}

\author{Héctor Laria Mantecón (662134) \and Maximilian Proll (662529)
  \and Aditya Kaushik Surikuchi (662862)}

\maketitle

\newcommand{\points}[1]{\par\noindent\textit{(#1 points)}}
\newcommand{\onepoint}{\par\noindent\textit{(1 point)}}
\newcommand{\defaulttext}[1]{\textit{\textcolor{red}{#1}}}

\begin{abstract}
  \defaulttext{Write an abstract of approximately 200 words. \\
  The overall length of your report in this format should be 6--8
  pages, including images, references and everything, in the format of
  this template.  You can choose to use any document template and
  typesetting facility as long as you submit your report as a PDF file.
  Use of figures and tables is strongly encouraged!\\
  The breakdown of the total 30 points of the mini project is shown
  below for all sections of the report. However, points will be given
  only for project reports that are complete, i.e.\@ they have
  relevant content in all sections.  Minimum of 10 points are required
  for passing the course.  \\
  The reports will be evaluated using the Turnitin plagiarism
  prevention tool to ensure that the reports are genuine work written
  for this course.}
  %% 
  \onepoint
\end{abstract}

\section{Introduction}

\defaulttext{Describe the machine learning problem you have addressed in your mini
project, your applied method and used data in general terms.}
%%
\points{2}

\section{Related work}

There are many proposed solutions for text classification problems. They involve both neural and non-neural techniques. Some of the prior work on Amazon movie reviews has shown that ensemble learning using derived features (like review length, product rating) which performed better in comparison to plain classification methods like SVMs or logistic regression.
Other work used contextual metadata features (like product category, reviewer details) which seemed to work when using non-neural models.

Around 2011, deep networks starting becoming popular after the conception of convolutional neural nets\cite{DBLP:journals/corr/Kim14f} for sentence classification. They started to consistently perform better compared to the conventional classification methods listed above. Gradually when RNNs (recurrent neural nets) came into picture researchers started to take advantage of the architecture. Specifically, the introduction of LSTMs started to revolutionize the challenging domains of speech recognition, machine translation and image captioning.

Owing to such growing popularity of LSTMs there were many deep network architectures researched, built and published leveraging multiple-layers of LSTMs for the natural language processing domain. One such notable work is for predicting product review helpfulness using a deep net arch with 2 LSTM layers along with sophisticated NLP features\cite{wei}. 
%%

\section{Method}

\defaulttext{Describe your chosen solution in sufficient detail.  Pay special
attention to describing the deep learning algorithm(s) you used.  Show
some essential equations and describe all hyper-parameters that are
involved in the method.}
%%
\points{3}

\section{Data}
\subsection{Description}

The data used for this mini project is the Amazon product review data by Julian McAuley from UC San Diego \cite{HeMcA16a} \cite{McATarShiHen15}. His data contains Amazon product reviews and metadata, including 142.8 million reviews spanning May 1996 - July 2014.
A product review in the dataset is build up by the following fields: \textit{reviewer ID}, \textit{asin} (product ID), \textit{helpful} (tuple of two integers $f_p$ and $f$), \textit{review Text}, \textit{overall} (rating out of five), \textit{summary} and \textit{category} (like books, electronics or digital music).
An exemplary review is displayed in Table~\ref{tab:JSON}. 

\begin{table}[h!]
\centering
 \begin{tabular}{l |c}
 JSON category & example review value \\ \hline
 reviewer ID & A2B73CL3QSYWLB \\ 
 asin & B000IBUP6A \\ 
 helpful & [3, 6] \\ 
review Text & This film was a minor letdown after reading all the five star reviews ... \\ 
 overall & 4.0 \\ 
 summary & Very Good Crime Film \\ 
 category & Amazon Instant Video
 \end{tabular}
 \captionsetup{justification=centering,margin=2cm}
 \caption{ Exemplary content of a sample review from the Amazon product review dataset}
 \label{tab:JSON}
\end{table}

A reduced 5-core version of the dataset can be downloaded from the \href{http://jmcauley.ucsd.edu/data/amazon/links.html}{website of Julian McAuley}. In the 5-core dataset each product review and user has at least five entries, which contains in total 18.2 million reviews. Additionally we filtered our reviews which had less than five helpfulness feedback votes, which reduces the remaining dataset to 3.0 million reviews.

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{pics/data_distribution.png}
\captionsetup{justification=centering,margin=2cm}
\caption{Distribution of helpfulness scores: \\ (left) for the filtered 5-core dataset, (right) after unskewing}
\label{pic:distri}
\end{figure}

After leaving out reviews with less than five helpfulness feedback votes we saw, that the distribution of helpfulness scores is not equally distributed but rather skewed, as nearly half of the 3.0 million reviews have a helpfulness score of greater than 0.8. This is displayed in Figure~\ref{pic:distri}. 

In order to evenly distribute the dataset the entire range of the helpfulness score, we unskewed the data by randomly selecting the same number of reviews within a 0.2 helpfulness-score-bucket. The process of unskewing left 1.1 million reviews roughly uniformily distributed in the final dataset.

After we tried to further analyze the full dataset we ran into memory issues as both machines in \textit{Paniikki} as well as servers such as \textit{force} couldn't cope with the vast number of reviews, which is why we decided to reduce the data by randomly sampling a subset of 50,000. 80\% of this dataset are used for both training and validation and the remaining 20\% are used for the final test.

\subsection{Preprocessing}

In order to standardize the raw text of all reviews we transformed the raw text into normalized 1-grams. The raw text is the concatenation of the \textit{summary} field and the \textit{reviewText} field. 
Additionally we preprocessed the data with the following operations:

\begin{enumerate}[(i)]
\item remove all capitalization
\item tokenize the text and remove whitespace, symbols, punctuation, numerals
\item for all tokens, we filtered out:
\begin{itemize}
\item English stopwords (according to the NLTK stopwords corpus)
\item tokens with less than three characters
\end{itemize}
\end{enumerate}

%\defaulttext{Tell where the data is from, what it contains, the number of samples
%in training, validation and test sets, the dimensional, etc.  Also
%describe the preprocessing stages applied by the providers of the data
%or by you yourselves.}
%%
%\points{3}

\section{Experiments}

\defaulttext{Explain the goal and implementation of your experiments.  Tell what
hyperparameters values you experimented with and what other
variations in the method you tested.}
%%
\points{5}

\section{Results}

\defaulttext{Give the results of your experiments in a table and explain them in
the text.  Some figures would be good here for illustration.  Refer to
the table(s) and image(s) in the text and describe them.}
%%
\points{5}

\section{Discussion}

\defaulttext{Discuss your results in comparison with comparable results your have
found in the literature and web.  Explain any other findings you made
while running the experiments.}
%%
\points{4}

\section{Conclusions}

\defaulttext{Give your final conclusions from the whole mini project and its results.}
%%
\points{3}

\section{References}

\bibliography{bibliography}{}
\bibliographystyle{acm}

\defaulttext{Most likely between 5--10 references to related works and results.}
%%
\points{2}

\section{Roles of the authors}

This mini project was designed to \textit{allow the students to use the theoretical knowledge gained during the course in real life practical machine learning challenges}. In order to fully accomplish this main goal we tried to always work as a team and participate in all tasks equally.

Regardless of this overall working principle we summarize the main tasks each member was involved in in Table~\ref{tab:roles}. This list contains only the most important responsibilities and must not be to mistaken with an overarching list of tasks and responsibilities.

\begin{table}[h!]
\centering
 \begin{tabular}{l |l}
 member 		& task \\ \hline
 Aditya		&  dataset analysis, architecture of DL model, data gathering, visualization, \\ 
 			& word embedding , measure accuracy, anatomical feature, reporting,  \\
			& scheduling tasks, debugging, remote server access\\ \hline
 Héctor 		&  remote server access, data gathering, measure accuracy, dataset analysis,\\
 			& anatomical feature, reporting, word embedding, scheduling tasks, debugging, \\
			& architecture of DL model, visualization\\ \hline
 Maximilian 	& word embedding ,reporting, anatomical feature, remote server access,\\
 			& measure accuracy, data gathering, dataset analysis, visualization, \\
			& architecture of DL model, scheduling tasks, debugging
 \end{tabular}
 \captionsetup{justification=centering,margin=2cm}
 \caption{Involvement of main tasks and responsibilities broken down to the team members}
 \label{tab:roles}
\end{table}

%\defaulttext{If you have more than one member in your mini project group, you need
%to explain in this section how the labor was divided between you and
%what were each one's roles in the project and its reporting.}

\end{document}