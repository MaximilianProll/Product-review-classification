\documentclass[a4paper,11pt]{article}

\usepackage[english]{babel} 			%% englische Sprache

\usepackage[latin1,applemac]{inputenc}	%% deutsche Umlaute wie normale
 								%% Buchstaben verwenden 
 								%% (ansonsten muesste ‰ durch a getippt werden)
\usepackage{a4wide} 				%% kleinere Seitenränder

\usepackage{amssymb,amsthm,amsfonts, amsmath}
								%% diverse Matheerweiterungen, z.B. \implies
 								%% diverse Matheerweiterungen, z.B. \mathbb{R}
%\usepackage{stmaryrd} 				%% weitere Symbole
\usepackage{epsfig} 					%% um eps-Dateien einzubinden (\epsfig{file=...})
\usepackage{longtable} 				%% fuer Tabellen ueber mehrere Seiten
\usepackage{color}
\usepackage{hyperref}
\usepackage{dsfont}
\usepackage{caption}
\usepackage{multirow}
\usepackage{float}

\hypersetup{						%get rid of red box around hyperlink
pdfborder = {0 0 0}
}

\usepackage{listings} 				% noice code inclusion
\usepackage{color}

\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\lstset{
	frame=single,
	language=Python,
	belowcaptionskip=1\baselineskip,
	breaklines=true,
	frame=tb,
	showstringspaces=false,
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\color{deepblue},
	emphstyle=\color{deepred},    		% Custom highlighting style
	stringstyle=\color{deepgreen},
	commentstyle=\itshape\color{deepgreen}
}


\begin{document}

\title{Title of the Mini Project\\
\normalsize (MP 004 Firing Neurons)}

\author{Héctor Laria Mantecón (662134) \and Maximilian Proll (662529)
  \and Aditya Kaushik Surikuchi (662862)}

\maketitle

\newcommand{\points}[1]{\par\noindent\textit{(#1 points)}}
\newcommand{\onepoint}{\par\noindent\textit{(1 point)}}
\newcommand{\defaulttext}[1]{\textit{\textcolor{red}{#1}}}

\begin{abstract}
  \defaulttext{Write an abstract of approximately 200 words. \\
  The overall length of your report in this format should be 6--8
  pages, including images, references and everything, in the format of
  this template.  You can choose to use any document template and
  typesetting facility as long as you submit your report as a PDF file.
  Use of figures and tables is strongly encouraged!\\
  The breakdown of the total 30 points of the mini project is shown
  below for all sections of the report. However, points will be given
  only for project reports that are complete, i.e.\@ they have
  relevant content in all sections.  Minimum of 10 points are required
  for passing the course.  \\
  The reports will be evaluated using the Turnitin plagiarism
  prevention tool to ensure that the reports are genuine work written
  for this course.}
  %% 
  \onepoint
\end{abstract}

\section{Introduction}

\defaulttext{Describe the machine learning problem you have addressed in your mini
project, your applied method and used data in general terms.}
%%
\points{2}

\section{Related work}

There are many proposed solutions for text classification problems. They involve both neural and non-neural techniques. Some of the prior work on Amazon movie reviews has shown that ensemble learning using derived features (like review length, product rating) which performed better in comparison to plain classification methods like SVMs or logistic regression.
Other work used contextual metadata features (like product category, reviewer details) which seemed to work when using non-neural models.

Around 2011, deep networks starting becoming popular after the conception of convolutional neural nets\cite{DBLP:journals/corr/Kim14f} for sentence classification. They started to consistently perform better compared to the conventional classification methods listed above. Gradually when RNNs (recurrent neural nets) came into picture researchers started to take advantage of the architecture. Specifically, the introduction of LSTMs started to revolutionize the challenging domains of speech recognition, machine translation and image captioning.

Owing to such growing popularity of LSTMs there were many deep network architectures researched, built and published leveraging multiple-layers of LSTMs for the natural language processing domain. One such notable work is for predicting product review helpfulness using a deep net arch with 2 LSTM layers along with sophisticated NLP features\cite{wei}. 
%%

\section{Method}

\defaulttext{Describe your chosen solution in sufficient detail.  Pay special
attention to describing the deep learning algorithm(s) you used.  Show
some essential equations and describe all hyper-parameters that are
involved in the method.}
%%
\points{3}

\section{Data}

For the \cite{HeMcA16a} and \cite{McATarShiHen15}
\defaulttext{Tell where the data is from, what it contains, the number of samples
in training, validation and test sets, the dimensional, etc.  Also
describe the preprocessing stages applied by the providers of the data
or by you yourselves.}
%%
\points{3}

\section{Experiments}

%\defaulttext{Explain the goal and implementation of your experiments.  Tell what
%hyperparameters values you experimented with and what other
%variations in the method you tested.}
%%%
%\points{5}

As stated in our methodology, we started evaluating baseline models to prove their assertions true. We found a very convincing architecture which performed very well on the test set, so we proceeded to implement in \textit{TensorFlow}. This library is of relatively easy use and has many modules already implemented. We also used \textit{nltk} for word stemming, \textit{gensim} for word embedding, \textit{pandas} to handle the datasets, \textit{sk-learn} for t-SNE computation and \textit{matplotlib} for visualizations.

The schema implemented is explained next. The design variations are discussed following to it.

\subsection{Main model framework}\label{sec:main_model_framework}
The approach, as seen in Figure\defaulttext{cite here, model picture}, is actually very intuitive. At the end we have one set of fully-connected layers with a softmax function. They are configured with length $75, 50$ and $30$, leakyRELU ($max(0.01x, x)$) as the activation function and dropout \cite{dropout:JMLR:v15:srivastava14a} as regularization This network is fed with a number of high-level input features. Namely:
\begin{description}
	\item[Product id, reviewer id, category, rating] We wanted to take into account the crucial relations of the product reviews with their source; the reviewer themself. I.e. some people explain thing more concisely than others. For that purpose we feed the network with those labels, taken directly from the dataset.
	
	The category also makes sense to appear, as some people have more expertise than other on certain areas. Which allows them to produce higher-quality reviews.
	
	The rating is also evident, as it's the numerical opinion of the product by the reviewer.
	
	\item[Anatomical encoder] We used an encoder to extract common Natural Language Processing features we found very valuables in the baseline model, like the number of tokens, the length of those, the number of characters in the token, etc. Which are produced by using techniques like:
	\begin{itemize}
		\item \textbf{Tf-idf featurization} \cite{tfidf:Ramos2003UsingTT} a statistic to measure how important a word is regarding the whole document. Which internally uses \textit{uni-gram normalization}.
		\item \textbf{Stemming} to reduce words to they root form, and use them as tokens.
		\item \textbf{Word2vec} \cite{word2vec:DBLP:journals/corr/abs-1301-3781} Word embeddings that produce a vector space, with each word corresponding to a vector in that space. Words that are related on a context are positioned close to each other. This help us creating a useful representation of the words.
	\end{itemize}
	
	\item[Logistic regression] We applied logistic regression with $l_2$ regularization to the td-idf features of the top 12.000 text reviews words, stemmed to reduce the set of $n$-grams to consider. We have two regression models to classify good and bad reviews respectively. There is only one hyper-parameter, a regularization variable to avoid overfitting. With simple binary search we could find the optimal value at $1$ for the good reviews dataset and $0.23$ for the bad reviews one.
	
	\item[Recurrent networks] A very well known recurrent neural network was used for modelling the temporal data, \textit{Long Short-Term Memory} nets \cite{Hochreiter:1997:LSM:1246443.1246450}. It was fed with a pre-trained \textit{word2vec} model of the reviews. We used 50 units for the configuration, the regularization method was \textit{dropout} and we applied \textit{Adam} \cite{adam:DBLP:journals/corr/KingmaB14} parameter optimizer.
\end{description}

After understanding, implementing and engineering the model training to use \textit{Paniikki} machines, we started with our own variations to try to improve the baseline performance or accuracy. The most remarkable ones are the following.

\subsection{GRUs}
LSTMs are just one type of recurrent cell. There are a wide range of different ones, with their own pros and cons. As explained in the methods section, we took into consideration Gated Recurrent Units \cite{gru:DBLP:journals/corr/ChungGCB14} (GRUs) because it was the most familiar to us.

We used the same configuration as for the LSTM units, with the same optimizer (Adam).

\subsection{Varying params}
We varied the following parameters and hyper-parameters of the neural network:
\begin{itemize}
	\item The number of units in each GRU cell. Ranging from 25 to 95 units with a step interval of 10, before concluding for 50.
	\item The number of GRU layers. The base paper empirically proved that 2 layered LSTM performed well in comparison to a single one. We started with the same premise and validated the same. We also noticed that increasing the number of layers further did not have any impact on the results. A reason we inferred for this is relies on the constraints of the number of features.
\end{itemize}

\subsection{Features relevance}
During the implementation, we questioned the utility of \textit{product id} and \textit{reviewer id} context features. We thought that feed some identifiers to the network don't make any sense. We tried to train the model without those features, which resulted into worse accuracy. By doing that we learn what Section \ref{sec:main_model_framework} explains.

\section{Results}

\defaulttext{Give the results of your experiments in a table and explain them in
	the text.  Some figures would be good here for illustration.  Refer to
	the table(s) and image(s) in the text and describe them.}
%%
\points{5}

table: time  performance
lstms
grus
nlp features

\subsection{LSTM vs GRU}

\section{Discussion}

\defaulttext{Discuss your results in comparison with comparable results your have
found in the literature and web.  Explain any other findings you made
while running the experiments.}
%%
\points{4}

\section{Conclusions}

\defaulttext{Give your final conclusions from the whole mini project and its results.}
%%
\points{3}

\section{References}

\bibliography{bibliography}{}
\bibliographystyle{acm}

\defaulttext{Most likely between 5--10 references to related works and results.}
%%
\points{2}

\section{Roles of the authors}

\defaulttext{If you have more than one member in your mini project group, you need
to explain in this section how the labor was divided between you and
what were each one's roles in the project and its reporting.}

\end{document}